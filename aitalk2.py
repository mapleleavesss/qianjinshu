import streamlit as st
import json
from aibackend2 import models, get_chat_response_from_gpt
from PIL import Image
import datetime

with open('initial_instruction.json', 'r', encoding='utf-8') as file:
    instruction = json.load(file)[0]

# å®šä¹‰é¡µé¢
st.set_page_config(layout="wide")
st.title("ğŸ¤– åƒé‡‘ä¹¦â€”â€”æŒä¸Šæ™ºèƒ½ç¥åŒ»")

model_id = st.sidebar.selectbox(label = 'è¯·é€‰æ‹©æ‚¨åå¥½çš„åŒ»ç–—å¯¹è¯åŸºæ¨¡å‹',
    options = [key for key,value in models.items()],
    help = 'æ¨èé»˜è®¤æ¨¡å‹',
    index=1)
 
image = Image.open('logo.jpg')
st.sidebar.image(image)

if 'date_time' not in st.session_state:
        st.session_state.date_time = None
st.session_state.date_time = datetime.datetime.now() 
st.sidebar.date_input('æ—¥æœŸ', st.session_state.date_time.date())    # æ˜¾ç¤ºæ—¥æœŸ
st.sidebar.time_input('æ—¶é—´', st.session_state.date_time.time())    # æ˜¾ç¤ºæ—¶é—´ 

st.sidebar.markdown('<br>', unsafe_allow_html=True)
st.session_state.tag = st.sidebar.button('å¼€å‘è€…ã€åŸºæ¨¡å‹ã€å¾®è°ƒæƒé‡ã€æ•°æ®é›†å’Œè®¡ç®—èµ„æºä»‹ç»')

if st.session_state.tag:
    model_id = None
    st.markdown("### åŸºæ¨¡å‹")
    st.markdown("-"*100)
    st.markdown("-"*100)
    st.markdown("### LoRAæ¨¡å‹æƒé‡")
    st.markdown("-"*100)
    st.markdown("-"*100)
    st.markdown("### æ•°æ®é›†")
    st.markdown("-"*100)
    st.markdown("-"*100)
    st.markdown("### è®¡ç®—èµ„æºéœ€æ±‚")
    st.markdown("-"*100)
    st.markdown("-"*100)
    
    button1 = st.button('è¿”å›')

st.sidebar.markdown('<br>'*3, unsafe_allow_html=True) 
# é»˜è®¤å¯ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡
# "ç‚¹å‡»â€œæ¸…ç©ºæ‰€æœ‰å¯¹è¯â€æŒ‰é’®åå°†æ¸…ç©ºä¸Šä¸‹æ–‡
buttonClean = st.sidebar.button("æ¸…ç†ä¼šè¯å†å²", key="clean")

if model_id:
    if buttonClean:
        st.session_state.messages = [{'role':"assistant", 'content':instruction}]

    # åˆå§‹åŒ–ä¼šè¯
    if "messages" not in st.session_state:
        st.session_state.messages =[{'role':"assistant", 'content':instruction}]


    # æ˜¾ç¤ºå†å²ä¼šè¯å†…å®¹
    for message in st.session_state.messages:
        st.chat_message(message['role']).write(message['content'])

    prompt = st.chat_input()
    if prompt:
        # å°†ç”¨æˆ·æç¤ºè¯å‚¨å­˜åœ¨ä¼šè¯ä¸­ï¼Œå¹¶æ˜¾ç¤ºåœ¨å¯¹è¯æ ä¸­
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        
        # è°ƒç”¨åç«¯å¤§æ¨¡å‹ç”Ÿæˆæ¥å£ï¼Œå¹¶å­˜å‚¨å’Œæ˜¾ç¤ºå¤§æ¨¡å‹çš„è¾“å‡º
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):    
            response = get_chat_response_from_gpt(st.session_state.messages, models[model_id])
            
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.chat_message("assistant").write(response)



